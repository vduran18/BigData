{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions\n",
    "spark = SparkSession.builder.appName('HW5').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, OneHotEncoderModel, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, Jan  8 2020, 13:42:34) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "# Python version \n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Unnamed: 0: integer (nullable = true)\n",
      " |-- event_time: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      "\n",
      "CPU times: user 4.36 ms, sys: 3.2 ms, total: 7.56 ms\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = spark.read.csv('eCommerce.csv', header = True, inferSchema = True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 ms, sys: 513 µs, total: 1.91 ms\n",
      "Wall time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Step 2: Prepare data for classification.\n",
    "\n",
    "# Create a new column which just uses first word before ‘.’ in category_code.\n",
    "split_col = functions.split(df['category_code'], '\\.')\n",
    "df_new = df.withColumn('category', split_col.getItem(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.63 ms, sys: 2.97 ms, total: 7.61 ms\n",
      "Wall time: 58.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Step 2: Prepare data for classification.\n",
    "\n",
    "# Use category_code, brand, and price as input variables.\n",
    "# Use event type as target variable.\n",
    "dat = df_new[['category', 'brand', 'price', 'event_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+----------+\n",
      "|   category|    brand|  price|event_type|\n",
      "+-----------+---------+-------+----------+\n",
      "|electronics|   huawei| 270.42|      view|\n",
      "|electronics|    yasin| 359.08|      view|\n",
      "| appliances|  almacom| 180.16|      view|\n",
      "|    apparel|  respect|  44.79|      view|\n",
      "|electronics|  samsung| 150.95|      view|\n",
      "|electronics|   xiaomi|  98.51|      cart|\n",
      "|electronics|    apple| 180.13|      view|\n",
      "|electronics|    casio|   27.0|      view|\n",
      "|electronics|  samsung| 385.85|      view|\n",
      "|electronics|  samsung| 396.15|      view|\n",
      "|  computers|     asus| 357.25|      view|\n",
      "|  computers|     acer| 437.57|      view|\n",
      "|electronics|    artel| 231.64|      view|\n",
      "|       kids|   chicco| 141.55|      view|\n",
      "|  furniture|      brw| 387.14|      view|\n",
      "| appliances|    artel|  93.62|      view|\n",
      "|electronics|  samsung| 130.99|      view|\n",
      "|electronics|     oris|1891.94|      view|\n",
      "|electronics|changhong| 359.37|      view|\n",
      "| appliances|  gorenje| 373.21|      view|\n",
      "+-----------+---------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.61 ms, sys: 5.99 ms, total: 12.6 ms\n",
      "Wall time: 66 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Step 2: Prepare data for classification.\n",
    "\n",
    "# Change categorical variables to numerical variables if necessary by using one-hot encoding. \n",
    "categoricalColumns = ['category', 'brand']\n",
    "stages = []\n",
    "\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = 'event_type', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "numericCols = ['price'] # Numerical Features\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      "\n",
      "CPU times: user 73.5 ms, sys: 21.4 ms, total: 94.9 ms\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(dat)\n",
    "dat_pipe = pipelineModel.transform(dat)\n",
    "selectedCols = ['label', 'features'] + dat.columns\n",
    "dat_select = dat_pipe.select(selectedCols)\n",
    "dat_select.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 6137234\n",
      "Test Dataset Count: 2627771\n",
      "CPU times: user 20.4 ms, sys: 22.1 ms, total: 42.5 ms\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, test = dat_select.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.4 ms, sys: 23.6 ms, total: 56 ms\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "|   category|  brand|price|label|       rawPrediction|prediction|         probability|\n",
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "|electronics|samsung| 5.64|  0.0|[1.81796790662471...|       0.0|[0.87965783234372...|\n",
      "|electronics|samsung| 5.64|  0.0|[1.81796790662471...|       0.0|[0.87965783234372...|\n",
      "|electronics|samsung| 6.16|  0.0|[1.81824177641175...|       0.0|[0.87970283194473...|\n",
      "|electronics|samsung| 6.22|  0.0|[1.81827337677180...|       0.0|[0.87970802325653...|\n",
      "|electronics|samsung| 6.67|  0.0|[1.81851037947213...|       0.0|[0.87974695183188...|\n",
      "|electronics|samsung| 6.67|  0.0|[1.81851037947213...|       0.0|[0.87974695183188...|\n",
      "|electronics|samsung| 6.67|  0.0|[1.81851037947213...|       0.0|[0.87974695183188...|\n",
      "|electronics|samsung| 6.67|  0.0|[1.81851037947213...|       0.0|[0.87974695183188...|\n",
      "|electronics|samsung| 6.67|  0.0|[1.81851037947213...|       0.0|[0.87974695183188...|\n",
      "|electronics|samsung| 6.67|  0.0|[1.81851037947213...|       0.0|[0.87974695183188...|\n",
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "predictions.select('category', 'brand', 'price', 'label', 'rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.6959880962948346\n",
      "CPU times: user 12.4 ms, sys: 10.1 ms, total: 22.5 ms\n",
      "Wall time: 56.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Step 3: Use Logistic Regression to perform classification on event type (view, cart, purchase).\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "predictions = lrModel.transform(test)\n",
    "predictions.select('category', 'brand', 'price', 'label', 'rawPrediction', 'prediction', 'probability').show(10)\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "|   category|  brand|price|label|       rawPrediction|prediction|         probability|\n",
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "|electronics|samsung| 5.64|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 5.64|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 6.16|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 6.22|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 6.67|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 6.67|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 6.67|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 6.67|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 6.67|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "|electronics|samsung| 6.67|  0.0|[5823074.0,186861...|       0.0|[0.94881081607773...|\n",
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Test Area Under ROC: 0.5\n",
      "CPU times: user 204 ms, sys: 144 ms, total: 347 ms\n",
      "Wall time: 27min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Step 3: Use decision tree to perform classification on event type (view, cart, purchase).\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
    "dtModel = dt.fit(train)\n",
    "predictions_dt = dtModel.transform(test)\n",
    "predictions_dt.select('category', 'brand', 'price', 'label', 'rawPrediction', 'prediction', 'probability').show(10)\n",
    "\n",
    "evaluator_dt = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator_dt.evaluate(predictions_dt, {evaluator_dt.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "|   category|  brand|price|label|       rawPrediction|prediction|         probability|\n",
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "|electronics|samsung| 5.64|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 5.64|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 6.16|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 6.22|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 6.67|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 6.67|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 6.67|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 6.67|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 6.67|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "|electronics|samsung| 6.67|  0.0|[18.9588981235038...|       0.0|[0.94794490617519...|\n",
      "+-----------+-------+-----+-----+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Test Area Under ROC: 0.6959739126935542\n",
      "CPU times: user 201 ms, sys: 139 ms, total: 340 ms\n",
      "Wall time: 27min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Step 3: Use random forest to perform classification on event type (view, cart, purchase). \n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "rfModel = rf.fit(train)\n",
    "predictions_rf = rfModel.transform(test)\n",
    "predictions_rf.select('category', 'brand', 'price', 'label', 'rawPrediction', 'prediction', 'probability').show(10)\n",
    "\n",
    "evaluator_rf = BinaryClassificationEvaluator()\n",
    "print(\"Test Area Under ROC: \" + str(evaluator_rf.evaluate(predictions, {evaluator_rf.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
